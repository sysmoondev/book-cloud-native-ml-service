# 2.2.3 Ingress Gateway

현재 Istio의 Ingress에서는 Gateway라는 리소스가 사용되고 있습니다.

(port, host, TLS key, certification같은 L4-L6 functions만을 설정할 수만 있다. )

Gateway는 Istio의 VirtualService 리소스와 바인딩할 수 있게 해줍니다. 그래서 mesh 내부에 들어오는 트래픽에 대해서 사용되는 라우팅 설정을 위해서 동일한 리소스가 사용된다.

istio를 설치하면 두가지 gateway에 대한 두개의 deployments가 설치되어 있음

Ingress gateway와 Egress 임

이 deployment를 더 자세히 살펴보면, pods들과 service들이 배포되어 있음

istio ingress gateway는 incoming traffic을 mesh내부의 특정 서비스로 라우팅해주고,

ingressgateway라는 deployment는 istio-system namespace에 설치되어 있다.

pods과 service도 마찬가지로 찾을 수 잇을 것이다.

```bash
kubectl get deployment -n istio-system                                                                                                                                                 [20:51:58]
NAME                   READY   UP-TO-DATE   AVAILABLE   AGE
istio-egressgateway    1/1     1            1           63d
istio-ingressgateway   1/1     1            1           63d
istiod                 1/1     1            1           63d
jaeger                 1/1     1            1           63d
kiali                  1/1     1            1           63d
prometheus             1/1     1            1           63d
```

이러한 커맨드로 host의 IP를 확인할 수 있다. istio-ingressgateway의 pod가 실행중인 host를 알 수 있따.

그리고 노출된 서비스의 port를 확인할 수 있다.

그래서 이것을 가지고 GATEWAY의 주소를 알아낼 수 잇다.

이 주소로 curl을 날리면 외부에서 mesh내부로 들어가는 gateway를 통하게 되는것이다.

하지만 위처럼 403에러가남, 이렇게 에러가 난 이유는 ingress controller를 attach하지 않았기 때문이다.

```bash
export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="http2")].port}')
export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="https")].port}')
export TCP_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="tcp")].port}')
```

Istios의 ingress는 바로 pod으로 들어감

0.8 release, Istio used Kubernetes Ingress resources

* Kubernetes Ingress can’t be managed by the Istio control plane
  * 결국 Kubernetes의 routing 설정도 따로 관리해야함 (복잡함)
* k8s의 ingress는 sidecars만큼의 피쳐를 제공해주지 않음 advanced routing rules, distributed tracing, policy checking, metrics collections

그래서 Kubernetes Ingress를 대체하기 위해서 나온것이 Istio Gateway이다.

(0.8버전 부터)

Istio Gateway는 K8S ingress보다 심플하다?

port, host, TLS key, certification같은 L4-L6 functions만을 설정할 수만 있다.

하지만 Gateway는 Istio의 VirtualService resource와 바인딩될 수 있다. 그래서 mesh 내부에 들어오는 트래픽에 대해서 사용되는 라우팅 설정을 위해서 동일한 리소스가 사용된다.

즉, Istio는 mesh의 진입점에서도 mesh내부에서와 동일한 capabilities를 제공한다. ingress gateway와 sidecar proxies는 mesh의 control plane에 의해 통합적으로 관리된다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4a901e89-42e6-4ed5-aaa9-49d034a9ec50/Untitled.png)

#### Istio Gateway 샘플 예제

Bookinfo 샘플 예제 참고

### Service Entry

서비스 항목을 사용하여 Istio가 내부적으로 유지 관리하는 서비스 레지스트리에 항목을 추가합니다. 서비스 항목을 추가한 후 Envoy 프록시는 마치 메시의 서비스인 것처럼 서비스에 트래픽을 보낼 수 있습니다. 서비스 항목을 구성하면 다음 작업을 포함하여 메시 외부에서 실행되는 서비스에 대한 트래픽을 관리할 수 있습니다.

메시 서비스에서 사용하려는 모든 외부 서비스에 대해 서비스 항목을 추가할 필요는 없습니다. 기본적으로 Istio는 알 수 없는 서비스에 요청을 전달하도록 Envoy 프록시를 구성합니다. 그러나 Istio 기능을 사용하여 메시에 등록되지 않은 대상으로의 트래픽을 제어할 수 없습니다.

#### Service Entry 샘플 예제

다음 예제 mesh-external 서비스 항목은 Istio의 서비스 레지스트리에 [ext-svc.example.com](http://ext-svc.example.com) 외부 종속성을 추가합니다.

```bash
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: svc-entry
spec:
  hosts:
  - ext-svc.example.com
  ports:
  - number: 443
    name: https
    protocol: HTTPS
  location: MESH_EXTERNAL
  resolution: DNS
```

호스트 필드를 사용하여 외부 리소스를 지정합니다. 완전히 한정하거나 와일드카드 접두사 도메인 이름을 사용할 수 있습니다.

메시의 다른 서비스에 대한 트래픽을 구성하는 것과 동일한 방식으로 서비스 항목에 대한 트래픽을 제어하도록 가상 서비스 및 대상 규칙을 구성할 수 있습니다. 예를 들어 다음 대상 규칙은 서비스 항목을 사용하여 구성한 [ext-svc.example.com](http://ext-svc.example.com) 외부 서비스에 대한 연결을 보호하기 위해 상호 TLS를 사용하도록 트래픽 경로를 구성합니다.

```bash
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: ext-res-dr
spec:
  host: ext-svc.example.com
  trafficPolicy:
    tls:
      mode: MUTUAL
      clientCertificate: /etc/certs/myclientcert.pem
      privateKey: /etc/certs/client_private_key.pem
      caCertificates: /etc/certs/rootcacerts.pem
```

더 많은 가능한 구성 옵션은 [서비스 항목](https://istio.io/latest/docs/reference/config/networking/service-entry/) 참조를 참조하십시오.

### Sidecars

기본적으로 Istio는 연결된 워크로드의 모든 포트에서 트래픽을 수락하고 트래픽을 전달할 때 메시의 모든 워크로드에 도달하도록 모든 Envoy 프록시를 구성합니다. 사이드카 구성을 사용하여 다음을 수행할 수 있습니다.

* Envoy 프록시가 허용하는 포트 및 프로토콜 집합을 미세 조정합니다.
* Envoy 프록시가 도달할 수 있는 서비스 집합을 제한합니다.

메시의 다른 모든 서비스에 도달하도록 모든 프록시를 구성하면 높은 메모리 사용량으로 인해 메시 성능에 잠재적으로 영향을 미칠 수 있는 대규모 애플리케이션에서 이와 같이 사이드카 도달 가능성을 제한할 수 있습니다.

사이드카 구성이 특정 네임스페이스의 모든 워크로드에 적용되도록 지정하거나 워크로드 선택기를 사용하여 특정 워크로드를 선택할 수 있습니다. 예를 들어 다음 사이드카 구성은 bookinfo 네임스페이스의 모든 서비스가 동일한 네임스페이스 및 Istio 제어 평면(현재 Istio의 정책 및 원격 측정 기능을 사용하는 데 필요)에서 실행되는 서비스에만 도달하도록 구성합니다.

```bash
apiVersion: networking.istio.io/v1alpha3
kind: Sidecar
metadata:
  name: default
  namespace: bookinfo
spec:
  egress:
  - hosts:
    - "./*"
    - "istio-system/*"
```

See the [Sidecar reference](https://istio.io/latest/docs/reference/config/networking/sidecar/) for more details.
